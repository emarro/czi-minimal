_target_: wrappers.hnet.build_model
_convert_: "all"
_modelstr_: "hnet_${model.arch_layout}_N=${model.default_target_ratio}"

arch_layout: ["M23"] #architecture for DNA from Table 7 with best PPL in HNet paper
d_model: [512, 512] #d_model of each stage (matches stages from arch_layout)
d_intermediate: [512, 768] # size of FFN sizes for MLP corresponding to above
vocab_size: 16
ssm_cfg:
  chunk_size: 256
  d_conv: 4
  d_state: 128
  expand: 2
attn_cfg:
  num_heads: [8, 8]
  rotary_emb_dim: [16, 32]
  window_size: [-1, -1]
tie_embeddings: False

pad_token_id: -100  # [PAD] token ID
ratio_loss_weight: 0.03 #alpha from the paper
use_return_dict: False

# Meta variables, not used in HNetConfig directly
default_target_ratio: null
max_seq_len: 512
mlm: False
log_bpreds: False
